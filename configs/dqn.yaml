## Run Parameters ##
run-title: dqn-cartpole-1
train: true 

## Environment ##
environment: LunarLander-v2 # {CartPole-v0, MountainCar-v0, LunarLander-v2, CarRacing-v0}
solved-criterion: 200 # {195, -110, 200, 900}
max-episode-steps: 1000 # {200, 200, 1000, 1000}

## DQN Variant ##
dqn-type: vanilla # {vanilla, double, dueling}

## Training ##
batch-size: 32
gamma: 0.99
episodes: 1000
train-freq: 4

## Replay Buffer ##
max-experiences: 50_000
min-experiences: 128

## Priortized Experience Replay ##
prioritized-replay: false 
p-alpha: 0.6
p-beta-init: 0.4
p-eps: 1.e-6

## Network ##
architecture:
  - 64
  - 128
  - 64

## Optimizer ##
lr-init: 5.e-4
lr-step: 25
lr-gamma: 0.9
weight-decay: 1.e-4

## Exploration ##
epsilon-start: 0.9
epsilon-min: 0.05
epsilon-decay: 0.99

## Target Update ##
use-soft-update: true
tau: 0.999
target-update: 10

## Paths ##
save-path: models
load-path: ./models/ddqn-lunar-v2.pt

## Visualize ##
visualize: false
vis-episodes: 10